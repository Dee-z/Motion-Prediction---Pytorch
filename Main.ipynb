{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Main.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"metadata":{"id":"lunklH6oQKJz","colab_type":"code","outputId":"31025b13-60da-474f-c2a6-8c48f12170e9","executionInfo":{"status":"ok","timestamp":1539190154063,"user_tz":-480,"elapsed":87914,"user":{"displayName":"Sự Huỳnh Văn","photoUrl":"","userId":"11872669261838445806"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n"],"name":"stdout"}]},{"metadata":{"id":"MuoGUSK2RMN8","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9Bnkr3jmRM4D","colab_type":"code","outputId":"8ee67e0c-8486-465d-8e14-0ae92b63ff96","executionInfo":{"status":"ok","timestamp":1535807974624,"user_tz":-480,"elapsed":32663,"user":{"displayName":"Sự Huỳnh Văn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"105091486446012976888"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"cell_type":"code","source":["!pip3 install http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting torch==0.4.1 from http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl\n","\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.4.1-cp36-cp36m-linux_x86_64.whl (483.0MB)\n","\u001b[K    100% |████████████████████████████████| 483.0MB 53.5MB/s \n","tcmalloc: large alloc 1073750016 bytes == 0x56320000 @  0x7f87fe88e1c4 0x46d6a4 0x5fcbcc 0x4c494d 0x54f3c4 0x553aaf 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54efc1 0x54f24d 0x551ee0 0x54efc1 0x54f24d 0x551ee0 0x54e4c8 0x54f4f6 0x553aaf 0x54e4c8\n","\u001b[?25hInstalling collected packages: torch\n","Successfully installed torch-0.4.1\n"],"name":"stdout"}]},{"metadata":{"id":"OzEFX6AvX01q","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"Z7wLeRqmRPAs","colab_type":"code","outputId":"043d9849-c2bb-4eec-830d-5b133b7d3951","executionInfo":{"status":"ok","timestamp":1535807980504,"user_tz":-480,"elapsed":4986,"user":{"displayName":"Sự Huỳnh Văn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"105091486446012976888"}},"colab":{"base_uri":"https://localhost:8080/","height":275}},"cell_type":"code","source":["!pip3 install torchvision"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting torchvision\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 3.9MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.5)\n","Collecting pillow>=4.1.1 (from torchvision)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/24/f53ff6b61b3d728b90934bddb4f03f8ab584a7f49299bf3bde56e2952612/Pillow-5.2.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K    100% |████████████████████████████████| 2.0MB 9.4MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Installing collected packages: pillow, torchvision\n","  Found existing installation: Pillow 4.0.0\n","    Uninstalling Pillow-4.0.0:\n","      Successfully uninstalled Pillow-4.0.0\n","Successfully installed pillow-5.2.0 torchvision-0.2.1\n"],"name":"stdout"}]},{"metadata":{"id":"ap80JAXYBxwh","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FftZg62yRRVU","colab_type":"code","colab":{}},"cell_type":"code","source":["!pwd"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qLKTWn-uRVpN","colab_type":"code","outputId":"6fc28ed8-4564-461b-a6ad-21b87541ba17","executionInfo":{"status":"ok","timestamp":1535808127994,"user_tz":-480,"elapsed":2131,"user":{"displayName":"Sự Huỳnh Văn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"105091486446012976888"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"cell_type":"code","source":["!ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["data\t  logs\t      models\t\t __pycache__\t train_lstm.py\r\n","dataset   Main.ipynb  pretrained_models  raw\t\t utils.py\r\n","datasets  model.pth   processed\t\t train_drnet.py\r\n"],"name":"stdout"}]},{"metadata":{"id":"6iQWEsg-RWC0","colab_type":"code","outputId":"36b93723-d853-4b82-e2cb-09867d1961ab","executionInfo":{"status":"ok","timestamp":1535808123800,"user_tz":-480,"elapsed":656,"user":{"displayName":"Sự Huỳnh Văn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"105091486446012976888"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["cd drive/PyTorch/Motion_prediction"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/PyTorch/Motion_prediction\n"],"name":"stdout"}]},{"metadata":{"id":"llWwfdEiBWc_","colab_type":"code","outputId":"1c25702a-c621-4902-e4af-1770083c3b99","executionInfo":{"status":"ok","timestamp":1535808117200,"user_tz":-480,"elapsed":799,"user":{"displayName":"Sự Huỳnh Văn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"105091486446012976888"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["cd .."],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"metadata":{"id":"2DpXF6CIRauk","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install Pillow==4.0.0\n","!pip install PIL\n","!pip install image\n","import PIL.image"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QJkvvs7Ddk7Q","colab_type":"text"},"cell_type":"markdown","source":["### Install progressbar"]},{"metadata":{"id":"gsVv_R57dkT4","colab_type":"code","outputId":"195b9b08-107c-4c06-9a0a-f40d44cbe1d7","executionInfo":{"status":"ok","timestamp":1535808030415,"user_tz":-480,"elapsed":3755,"user":{"displayName":"Sự Huỳnh Văn","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"105091486446012976888"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"cell_type":"code","source":["!pip3 install progressbar"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting progressbar\n","  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n","Building wheels for collected packages: progressbar\n","  Running setup.py bdist_wheel for progressbar ... \u001b[?25l-\b \bdone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n","Successfully built progressbar\n","Installing collected packages: progressbar\n","Successfully installed progressbar-2.5\n"],"name":"stdout"}]},{"metadata":{"id":"9msH-qxBRl2z","colab_type":"code","colab":{}},"cell_type":"code","source":["!python drive/PyTorch/starting_with_codelab/simple_gan.py"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JW4IESXyU4rl","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","dataset_path='dataset/mnist_test_seq.npy'\n","motion_mnist=np.load(dataset_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"HzFR3xdlWz5V","colab_type":"code","colab":{}},"cell_type":"code","source":["a=motion_mnist[:,1,:,:]\n","a.shape\n","plt.ion()\n","for i in range(20):\n","  plt.figure(1); plt.clf()\n","  plt.imshow(a[i,:,:])\n","  plt.title('Number ' + str(i))\n","  plt.pause(.3)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GhCT7Af_UyMo","colab_type":"text"},"cell_type":"markdown","source":["### Train New GAN"]},{"metadata":{"id":"I4K4wz1WWJL7","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","import torch\n","import torchvision\n","import torch.nn as nn\n","from torchvision import transforms\n","from torchvision.utils import save_image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Hyper-parameters\n","latent_size = 64\n","hidden_size = 256\n","image_size = 784\n","num_epochs = 5\n","batch_size = 100\n","sample_dir = 'samples'\n","\n","# Create a directory if not exists\n","if not os.path.exists(sample_dir):\n","    os.makedirs(sample_dir)\n","\n","# Image processing\n","transform = transforms.Compose([\n","                transforms.ToTensor(),\n","                transforms.Normalize(mean=(0.5, 0.5, 0.5),   # 3 for RGB channels\n","                                     std=(0.5, 0.5, 0.5))])\n","\n","# MNIST dataset\n","mnist = torchvision.datasets.MNIST(root='../../data/',\n","                                   train=True,\n","                                   transform=transform,\n","                                   download=True)\n","\n","# Data loader\n","data_loader = torch.utils.data.DataLoader(dataset=mnist,\n","                                          batch_size=batch_size, \n","                                          shuffle=True)\n","\n","# Discriminator\n","D = nn.Sequential(\n","    nn.Linear(image_size, hidden_size),\n","    nn.LeakyReLU(0.2),\n","    nn.Linear(hidden_size, hidden_size),\n","    nn.LeakyReLU(0.2),\n","    nn.Linear(hidden_size, 1),\n","    nn.Sigmoid())\n","\n","# Generator \n","G = nn.Sequential(\n","    nn.Linear(latent_size, hidden_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_size, hidden_size),\n","    nn.ReLU(),\n","    nn.Linear(hidden_size, image_size),\n","    nn.Tanh())\n","\n","# Device setting\n","D = D.to(device)\n","G = G.to(device)\n","\n","# Binary cross entropy loss and optimizer\n","criterion = nn.BCELoss()\n","d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n","g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n","\n","def denorm(x):\n","    out = (x + 1) / 2\n","    return out.clamp(0, 1)\n","\n","def reset_grad():\n","    d_optimizer.zero_grad()\n","    g_optimizer.zero_grad()\n","\n","# Start training\n","total_step = len(data_loader)\n","for epoch in range(num_epochs):\n","    for i, (images, _) in enumerate(data_loader):\n","        images = images.reshape(batch_size, -1).to(device)\n","        \n","        # Create the labels which are later used as input for the BCE loss\n","        real_labels = torch.ones(batch_size, 1).to(device)\n","        fake_labels = torch.zeros(batch_size, 1).to(device)\n","\n","        # ================================================================== #\n","        #                      Train the discriminator                       #\n","        # ================================================================== #\n","\n","        # Compute BCE_Loss using real images where BCE_Loss(x, y): - y * log(D(x)) - (1-y) * log(1 - D(x))\n","        # Second term of the loss is always zero since real_labels == 1\n","        outputs = D(images)\n","        d_loss_real = criterion(outputs, real_labels)\n","        real_score = outputs\n","        \n","        # Compute BCELoss using fake images\n","        # First term of the loss is always zero since fake_labels == 0\n","        z = torch.randn(batch_size, latent_size).to(device)\n","        fake_images = G(z)\n","        outputs = D(fake_images)\n","        d_loss_fake = criterion(outputs, fake_labels)\n","        fake_score = outputs\n","        \n","        # Backprop and optimize\n","        d_loss = d_loss_real + d_loss_fake\n","        reset_grad()\n","        d_loss.backward()\n","        d_optimizer.step()\n","        \n","        # ================================================================== #\n","        #                        Train the generator                         #\n","        # ================================================================== #\n","\n","        # Compute loss with fake images\n","        z = torch.randn(batch_size, latent_size).to(device)\n","        fake_images = G(z)\n","        #print('output size is:',fake_images.shape)\n","        outputs = D(fake_images)\n","        \n","        # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n","        # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n","        g_loss = criterion(outputs, real_labels)\n","        \n","        # Backprop and optimize\n","        reset_grad()\n","        g_loss.backward()\n","        g_optimizer.step()\n","        \n","        if (i+1) % 200 == 0:\n","            print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n","                  .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n","                          real_score.mean().item(), fake_score.mean().item()))\n","            print('output size is:',outputs.shape)\n","            for i in range(4):\n","              plt.subplot(2,2,i+1)\n","              plt.imshow(np.reshape(fake_images.data.cpu().numpy()[i], (28, 28)), cmap='gray')\n","            plt.show()\n","    \n","    # Save real images\n","    #if (epoch+1) == 1:\n","    #    images = images.reshape(images.size(0), 1, 28, 28)\n","    #    save_image(denorm(images), os.path.join(sample_dir, 'real_images.png'))\n","    \n","    # Save sampled images\n","    fake_images = fake_images.reshape(fake_images.size(0), 1, 28, 28)\n","    print('fake_images.size')\n","    save_image(fake_images, os.path.join(sample_dir, 'fake_images-{}.png'.format(epoch+1)))\n","\n","# Save the model checkpoints \n","torch.save(G.state_dict(), 'G.ckpt')\n","torch.save(D.state_dict(), 'D.ckpt')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CLwEH_QFCVzm","colab_type":"text"},"cell_type":"markdown","source":["### Train DR Net"]},{"metadata":{"id":"hakO6DOMCUzh","colab_type":"code","outputId":"6ab2c4b5-b387-4ce3-e916-c48a8a3af471","colab":{"base_uri":"https://localhost:8080/","height":108094,"output_embedded_package_id":"1wCAHDK1IaWN40EphMwaQtkCejjLDFxWS"}},"cell_type":"code","source":["# lam nhu trong paper\n","\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import argparse\n","import os\n","import random\n","import numpy as np\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import utils\n","import itertools\n","import progressbar\n","\n","from data.moving_mnist import MovingMNIST\n","import matplotlib.pyplot as plt\n","\n","\n","## hyper parameter\n","\n","lr=0.002\n","beta1=0.9\n","batch_size=100\n","log_dir='logs'\n","\n","data_root_x=''\n","optimizer='adam'\n","niter=200\n","seed=1\n","epoch_size=600\n","content_dim=128\n","pose_dim=5\n","image_width=64\n","channels=3\n","dataset='moving_mnist'\n","\n","max_step=20\n","sd_weight=0.1\n","sd_nf=100\n","content_model='dcgan'\n","pose_model='dcgan'\n","data_threads=0\n","normalize='store_true'\n","data_type='drnet'\n","\n","\n","\n","\n","name = 'content_model=%s\\npose_model=%s\\ncontent_dim=%d\\npose_dim=%d\\nmax_step=%d\\nsd_weight=%.3f\\nlr=%.3f\\nsd_nf=%d\\nnormalize=%s' % (content_model, pose_model, content_dim, pose_dim, max_step, sd_weight, lr, sd_nf, normalize)\n","log_dir = '%s/%s%dx%d/%s' % (log_dir, dataset, image_width, image_width, 'xxx')\n","\n","os.makedirs('%s/rec/' % log_dir, exist_ok=True)\n","os.makedirs('%s/analogy/' % log_dir, exist_ok=True)\n","\n","print(name)\n","\n","print(log_dir)\n","\n","print(\"Random Seed: \", seed)\n","random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","dtype = torch.cuda.FloatTensor\n","\n","if image_width == 64:\n","    import models.resnet_64 as resnet_models\n","    import models.dcgan_64 as dcgan_models\n","    import models.dcgan_unet_64 as dcgan_unet_models\n","    import models.vgg_unet_64 as vgg_unet_models\n","\n","if content_model == 'dcgan':\n","    netEC = dcgan_models.content_encoder(content_dim, channels)\n","    netD = dcgan_models.decoder(content_dim, pose_dim, channels)\n","\n","else:\n","    raise ValueError('Unknown content model: %s' % content_model)\n","\n","if pose_model == 'dcgan':\n","    netEP = dcgan_models.pose_encoder(pose_dim, channels, normalize=normalize)\n","else:\n","    raise ValueError('Unknown pose model: %s' % pose_model)   \n","    \n","       \n","import models.classifiers as classifiers\n","netC = classifiers.scene_discriminator(pose_dim, sd_nf)\n","\n","netEC.apply(utils.init_weights)\n","netEP.apply(utils.init_weights)\n","netD.apply(utils.init_weights)\n","netC.apply(utils.init_weights)\n","    \n","  \n","# ---------------- optimizers ----------------\n","\n","if optimizer == 'adam':\n","    optimizer = optim.Adam\n","else:\n","  raise ValueError('Unknown optimizer: %s' % optimizer)\n","\n","optimizerC = optimizer(netC.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerEC = optimizer(netEC.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerEP = optimizer(netEP.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerD = optimizer(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","    \n","# --------- loss functions ------------------------------------\n","mse_criterion = nn.MSELoss()\n","bce_criterion = nn.BCELoss()\n","\n","# --------- transfer to gpu ------------------------------------\n","netEP.cuda()\n","netEC.cuda()\n","netD.cuda()\n","netC.cuda()\n","mse_criterion.cuda()\n","bce_criterion.cuda()\n","\n","\n","# --------- load a dataset ------------------------------------\n","\n","train_data, test_data = utils.load_dataset(dataset,data_root_x,max_step,image_width,data_type)\n","\n","train_loader = DataLoader(train_data,\n","                          num_workers=data_threads,\n","                          batch_size=batch_size,\n","                          shuffle=True,\n","                          drop_last=True,\n","                          pin_memory=True)\n","test_loader = DataLoader(test_data,\n","                         num_workers=data_threads,\n","                         batch_size=batch_size,\n","                         shuffle=True,\n","                         drop_last=True,\n","                         pin_memory=True)\n","\n","\n","print(vars(train_loader))\n","\n","\n","def get_training_batch():\n","    while True:\n","        for sequence in train_loader:\n","            batch = utils.normalize_data(dataset,channels, dtype, sequence)\n","            yield batch\n","training_batch_generator = get_training_batch()\n","\n","def get_testing_batch():\n","    while True:\n","        for sequence in test_loader:\n","            \n","            batch = utils.normalize_data(dataset,channels, dtype, sequence)\n","            yield batch\n","testing_batch_generator = get_testing_batch()\n","\n","\n","# --------- plotting funtions ------------------------------------\n","\n","def plot_rec(x, epoch):\n","      x_c = x[0]\n","      x_p = x[np.random.randint(1, max_step)]\n","\n","      h_c = netEC(x_c)\n","      h_p = netEP(x_p)\n","      \n","      h_motion=torch.cuda.FloatTensor(100,5,1,1).fill_(0)\n","      h_content=torch.cuda.FloatTensor(100,128,1,1).fill_(0)  \n","#       h4_c=torch.cuda.FloatTensor(100,512,4,4).fill_(0) \n","#       h3_c=torch.cuda.FloatTensor(100,256,8,8).fill_(0) \n","#       h2_c=torch.cuda.FloatTensor(100,128,16,16).fill_(0) \n","#       h1_c=torch.cuda.FloatTensor(100,64,32,32).fill_(0) \n","      \n","#       h_content=[h5_c,[h1_c,h2_c,h3_c,h4_c]]\n","      \n","      rec = netD([h_c, h_p])\n","      rec_motion = netD([h_content, h_p])\n","      rec_content = netD([h_c, h_motion])\n","      \n","\n","      rec_=rec.cpu().detach().numpy()\n","      rec_motion_= rec_motion.cpu().detach().numpy()\n","      rec_content_ = rec_content.cpu().detach().numpy()\n","      \n","      \n","      \n","#       print(type(h_c))\n","      \n","#       print('len1:',len(h_c))\n","#       print('len2:',len(h_c[0]))\n","#       print('len3:',len(h_c[0][0]))\n","#       print('len4:',len(h_c[0][0][0]))\n","#       print('len5:',len(h_c[0][0][0][0]))\n","    \n","    \n","#       print('len1:',len(h_p))\n","#       print('len2:',len(h_p[0]))\n","#       print('len3:',len(h_p[0][0]))\n","#       print('len3:',len(h_p[0][0][0]))\n","      \n","    \n","    \n","      \n","#       print(type(h_p))\n","#       print(\"motion size; \",h_p.shape)\n","      \n","      \n","      #### show output size cua 1 model\n","      \n","#       h_c_=h_c\n","#       h_p_=h_p      \n","#       print('size of motion output: ', h_p_.size())\n","#       print('size of content output: ', h_c_.size())\n","      \n","  \n","      print('reconstruction from motion and content ')\n","      for i in range(2):\n","        plt.subplot(1,2,i+1)\n","        plt.imshow(np.transpose(rec_[i],(1,2,0)))\n","      plt.show()\n","      \n","      print('reconstruction from motion ')\n","      for i in range(2):\n","        plt.subplot(1,2,i+1)\n","        plt.imshow(np.transpose(rec_motion_[i],(1,2,0)))\n","      plt.show()\n","      \n","      print('reconstruction from content ')\n","      for i in range(2):\n","        plt.subplot(1,2,i+1)\n","        plt.imshow(np.transpose(rec_content_[i],(1,2,0)))\n","      plt.show()\n","                   \n","\n","        \n","        \n","def plot_analogy(x, epoch):\n","    x_c = x[0]\n","\n","    h_c = netEC(x_c)\n","    nrow = 10\n","    row_sz = max_step \n","    to_plot = []\n","    row = [xi[0].data for xi in x]\n","    zeros = torch.zeros(channels, image_width, image_width)\n","    to_plot.append([zeros] + row)\n","    for i in range(nrow):\n","        to_plot.append([x[0][i].data])\n","\n","    for j in range(0, row_sz):\n","        h_p = netEP(x[j]).data\n","        for i in range(nrow):\n","            h_p[i] = h_p[0]\n","        rec = netD([h_c, Variable(h_p)])\n","        for i in range(nrow):\n","            to_plot[i+1].append(rec[i].data.clone())\n","\n","    fname = '%s/analogy/%d.png' % (log_dir, epoch) \n","    utils.save_tensors_image(fname, to_plot)\n","\n","   \n","    \n","\n","# --------- training funtions ------------------------------------\n","def train(x):\n","    netEP.zero_grad()\n","    netEC.zero_grad()\n","    netD.zero_grad()\n","\n","    x_c1 = x[np.random.randint(4, max_step)]\n","    x_c2 = x[0]\n","    x_p1 = x[np.random.randint(4, max_step)]\n","    x_p2 = x[3]\n","\n","    h_c1 = netEC(x_c1)\n","    h_c2 = netEC(x_c2)[0].detach() if content_model[-4:] == 'unet' else netEC(x_c2).detach() # used as target for sim loss\n","    h_p1 = netEP(x_p1) # used for scene discriminator\n","    h_p2 = netEP(x_p2).detach()\n","\n","\n","    # similarity loss: ||h_c1 - h_c2||\n","    sim_loss = mse_criterion(h_c1[0] if content_model[-4:] == 'unet' else h_c1, h_c2)\n","\n","\n","    # reconstruction loss: ||D(h_c1, h_p1), x_p1|| \n","    rec = netD([h_c1, h_p1])\n","    rec_loss = mse_criterion(rec, x_p1)\n","\n","    # scene discriminator loss: maximize entropy of output\n","    target = torch.cuda.FloatTensor(batch_size, 1).fill_(0.5)\n","    out = netC([h_p1, h_p2])\n","    sd_loss = bce_criterion(out, Variable(target))\n","\n","    # full loss\n","    loss = sim_loss + rec_loss + sd_weight*sd_loss\n","    loss.backward()\n","\n","    optimizerEC.step()\n","    optimizerEP.step()\n","    optimizerD.step()\n","\n","    return sim_loss.data.cpu().numpy(),rec_loss.data.cpu().numpy(), sd_loss.data.cpu().numpy() \n","\n","  \n","def train_scene_discriminator(x):\n","  \n","    netC.zero_grad() ############# Sets gradients of all model parameters to zero.\n","\n","    target = torch.cuda.FloatTensor(batch_size, 1)\n","\n","    x1 = x[0]\n","    x2 = x[9]\n","    \n","    h_p1 = netEP(x1).detach()\n","    h_p2 = netEP(x2).detach()\n","\n","    half = int(batch_size/2)\n","    rp = torch.randperm(half).cuda()\n","    h_p2[:half] = h_p2[rp]\n","    target[:half] = 1\n","    target[half:] = 0\n","\n","    out = netC([h_p1, h_p2])\n","    bce = bce_criterion(out, Variable(target))\n","\n","    bce.backward()\n","    optimizerC.step()\n","\n","    acc =out[:half].gt(0.5).sum() + out[half:].le(0.5).sum()\n","    return bce.data.cpu().numpy(), acc.data.cpu().numpy()/batch_size\n","\n","\n","  \n","# --------- training loop ------------------------------------\n","for epoch in range(niter):\n","  \n","    netEP.train()\n","    netEC.train()\n","    netD.train()\n","    netC.train()\n","    \n","    epoch_sim_loss, epoch_rec_loss, epoch_sd_loss, epoch_sd_acc = 0, 0, 0, 0\n","\n","    progress = progressbar.ProgressBar(maxval=epoch_size).start()\n","    for i in range(epoch_size):\n","        progress.update(i+1)\n","        x = next(training_batch_generator)\n","\n","        # train scene discriminator\n","        _, sd_acc = train_scene_discriminator(x)\n","#         epoch_sd_loss += sd_loss\n","        epoch_sd_acc += sd_acc\n","\n","        # train main model\n","        sim_loss, rec_loss, sd_loss = train(x)\n","        epoch_sd_loss += sd_loss\n","        epoch_sim_loss += sim_loss\n","        epoch_rec_loss += rec_loss\n","        \n","#         if (epoch_size+1) % 2 == 0:\n","#           print('type of x: ',type(x))\n","#           print('size of x: ', len(x))\n","          \n","#           print('size of x: ', len(x[1]))\n","#           print('size of x: ', len(x[1][1]))\n","#           print('size of x: ', len(x[1][1][1]))\n","          \n","\n","\n","    progress.finish()\n","    utils.clear_progressbar()\n","\n","    netEP.eval()\n","    netEC.eval()\n","    netD.eval()\n","    # plot some stuff\n","    x = next(testing_batch_generator)\n","    plot_rec(x, epoch)\n","    \n","\n","    print('[%02d] rec loss: %.4f | sim loss: %.6f | scene disc acc: %.3f%% | sd_loss: %.4f (%d)' % (epoch, epoch_rec_loss/epoch_size, epoch_sim_loss/epoch_size, 100*epoch_sd_acc/epoch_size, epoch_sd_loss/epoch_size, epoch*epoch_size))\n","\n","    # save the model\n","    \n","    if (epoch+1) % 20 ==0:\n","      state = {'epoch': epoch + 1, '\n","               \n","               ': netD.state_dict(), 'state_dict_netEP': netEP.state_dict(), 'state_dict_netEC': netEC.state_dict(), 'state_dict_netC': netC.state_dict(),\n","             'optimizerC': optimizerC.state_dict(), 'optimizerD': optimizerD.state_dict(), 'optimizerEP': optimizerEP.state_dict(), 'optimizerEC': optimizerEC.state_dict(),}\n","      torch.save(state, '%s/model_state_dcgan_like_paper_epoch_%d.pth' % (log_dir,epoch+1))\n","    \n","    \n"," \n","\n","    \n","#     torch.save({\n","#         'netD': netD,\n","#         'netEP': netEP,\n","#         'netEC': netEC,},\n","#         '%s/model.pth' % log_dir)"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"metadata":{"id":"NfHDn1kWL0NK","colab_type":"text"},"cell_type":"markdown","source":["### Load model and continue training"]},{"metadata":{"id":"EKdFAJvkd4ZD","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import argparse\n","import os\n","import random\n","import numpy as np\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import utils\n","import itertools\n","import progressbar\n","\n","from data.moving_mnist import MovingMNIST\n","import matplotlib.pyplot as plt\n","\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","## hyper parameter\n","\n","lr=0.002\n","beta1=0.9\n","batch_size=100\n","log_dir='logs'\n","\n","data_root_x=''\n","optimizer='adam'\n","niter=260\n","seed=1\n","epoch_size=600\n","content_dim=128\n","pose_dim=10\n","image_width=64\n","channels=3\n","dataset='moving_mnist'\n","\n","max_step=20\n","sd_weight=0.05\n","sd_nf=100\n","content_model='dcgan_unet'\n","pose_model='dcgan'\n","data_threads=0\n","normalize='store_true'\n","data_type='drnet'\n","\n","\n","\n","\n","name = 'content_model=%s\\npose_model=%s\\ncontent_dim=%d\\npose_dim=%d\\nmax_step=%d\\nsd_weight=%.3f\\nlr=%.3f\\nsd_nf=%d\\nnormalize=%s' % (content_model, pose_model, content_dim, pose_dim, max_step, sd_weight, lr, sd_nf, normalize)\n","log_dir = '%s/%s%dx%d/%s' % (log_dir, dataset, image_width, image_width, 'xxx')\n","\n","# os.makedirs('%s/rec/' % log_dir, exist_ok=True)\n","# os.makedirs('%s/analogy/' % log_dir, exist_ok=True)\n","\n","print(name)\n","\n","print(log_dir)\n","\n","print(\"Random Seed: \", seed)\n","random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","dtype = torch.cuda.FloatTensor\n","\n","if image_width == 64:\n","    import models.resnet_64 as resnet_models\n","    import models.dcgan_64 as dcgan_models\n","    import models.dcgan_unet_64 as dcgan_unet_models\n","    import models.vgg_unet_64 as vgg_unet_models\n","\n","if content_model == 'dcgan_unet':\n","    netEC = dcgan_unet_models.content_encoder(content_dim, channels)\n","    netD = dcgan_unet_models.decoder(content_dim, pose_dim, channels)\n","\n","else:\n","    raise ValueError('Unknown content model: %s' % content_model)\n","\n","if pose_model == 'dcgan':\n","    netEP = dcgan_models.pose_encoder(pose_dim, channels, normalize=normalize)\n","else:\n","    raise ValueError('Unknown pose model: %s' % pose_model)   \n","    \n","       \n","import models.classifiers as classifiers\n","netC = classifiers.scene_discriminator(pose_dim, sd_nf)\n","\n","# netEC.apply(utils.init_weights)\n","# netEP.apply(utils.init_weights)\n","# netD.apply(utils.init_weights)\n","# netC.apply(utils.init_weights)\n","    \n","  \n","# ---------------- optimizers ----------------\n","\n","if optimizer == 'adam':\n","    optimizer = optim.Adam\n","else:\n","  raise ValueError('Unknown optimizer: %s' % optimizer)\n","\n","optimizerC = optimizer(netC.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerEC = optimizer(netEC.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerEP = optimizer(netEP.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerD = optimizer(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","  \n","# -------------------- load model, optimizer and epoch ---------------  \n","\n","checkpoint = torch.load('%s/model_state_epoch_100.pth' % log_dir)\n","\n","start_epoch = checkpoint['epoch']\n","\n","netD.load_state_dict(checkpoint['state_dict_netD'])\n","optimizerD.load_state_dict(checkpoint['optimizerD'])\n","\n","netC.load_state_dict(checkpoint['state_dict_netC'])\n","optimizerC.load_state_dict(checkpoint['optimizerC'])\n","\n","netEP.load_state_dict(checkpoint['state_dict_netEP'])\n","optimizerEP.load_state_dict(checkpoint['optimizerEP'])\n","\n","netEC.load_state_dict(checkpoint['state_dict_netEC'])\n","optimizerEC.load_state_dict(checkpoint['optimizerEC'])\n","\n","    \n","# --------- loss functions ------------------------------------\n","mse_criterion = nn.MSELoss()\n","bce_criterion = nn.BCELoss()\n","\n","# --------- transfer to gpu ------------------------------------\n","netEP.cuda()\n","netEC.cuda()\n","netD.cuda()\n","netC.cuda()\n","mse_criterion.cuda()\n","bce_criterion.cuda()\n","\n","#-----------transfer optimizer to gpu\n","\n","# now individually transfer the optimizer parts...\n","for state in optimizerD.state.values():\n","  for k, v in state.items():\n","    if isinstance(v, torch.Tensor):\n","      state[k] = v.to(device)\n","      \n","for state in optimizerC.state.values():\n","  for k, v in state.items():\n","    if isinstance(v, torch.Tensor):\n","      state[k] = v.to(device)      \n","      \n","for state in optimizerEP.state.values():\n","  for k, v in state.items():\n","    if isinstance(v, torch.Tensor):\n","      state[k] = v.to(device)     \n","      \n","\n","for state in optimizerEC.state.values():\n","  for k, v in state.items():\n","    if isinstance(v, torch.Tensor):\n","      state[k] = v.to(device)      \n","      \n","\n","# --------- load a dataset ------------------------------------\n","\n","train_data, test_data = utils.load_dataset(dataset,data_root_x,max_step,image_width,data_type)\n","\n","train_loader = DataLoader(train_data,\n","                          num_workers=data_threads,\n","                          batch_size=batch_size,\n","                          shuffle=True,\n","                          drop_last=True,\n","                          pin_memory=True)\n","test_loader = DataLoader(test_data,\n","                         num_workers=data_threads,\n","                         batch_size=batch_size,\n","                         shuffle=True,\n","                         drop_last=True,\n","                         pin_memory=True)\n","\n","\n","print(vars(train_loader))\n","\n","\n","def get_training_batch():\n","    while True:\n","        for sequence in train_loader:\n","            batch = utils.normalize_data(dataset,channels, dtype, sequence)\n","            yield batch\n","training_batch_generator = get_training_batch()\n","\n","def get_testing_batch():\n","    while True:\n","        for sequence in test_loader:\n","            \n","            batch = utils.normalize_data(dataset,channels, dtype, sequence)\n","            yield batch\n","testing_batch_generator = get_testing_batch()\n","\n","\n","# --------- plotting funtions ------------------------------------\n","\n","def plot_rec(x, epoch):\n","      x_c = x[0]\n","      x_p = x[np.random.randint(1, max_step)]\n","\n","      h_c = netEC(x_c)\n","      h_p = netEP(x_p)\n","      \n","      h_motion=torch.cuda.FloatTensor(100,10,1,1).fill_(0)\n","      h5_c=torch.cuda.FloatTensor(100,128,1,1).fill_(0)  \n","      h4_c=torch.cuda.FloatTensor(100,512,4,4).fill_(0) \n","      h3_c=torch.cuda.FloatTensor(100,256,8,8).fill_(0) \n","      h2_c=torch.cuda.FloatTensor(100,128,16,16).fill_(0) \n","      h1_c=torch.cuda.FloatTensor(100,64,32,32).fill_(0) \n","      \n","      h_content=[h5_c,[h1_c,h2_c,h3_c,h4_c]]\n","      \n","      rec = netD([h_c, h_p])\n","      rec_motion = netD([h_content, h_p])\n","      rec_content = netD([h_c, h_motion])\n","      \n","\n","      rec_=rec.cpu().detach().numpy()\n","      rec_motion_= rec_motion.cpu().detach().numpy()\n","      rec_content_ = rec_content.cpu().detach().numpy()\n","      \n","      \n","      \n","#       print(type(h_c))\n","      \n","#       print('len1:',len(h_c))\n","#       print('len2:',len(h_c[0]))\n","#       print('len3:',len(h_c[0][0]))\n","#       print('len4:',len(h_c[0][0][0]))\n","#       print('len5:',len(h_c[0][0][0][0]))\n","    \n","    \n","#       print('len1:',len(h_p))\n","#       print('len2:',len(h_p[0]))\n","#       print('len3:',len(h_p[0][0]))\n","#       print('len3:',len(h_p[0][0][0]))\n","      \n","    \n","    \n","      \n","#       print(type(h_p))\n","#       print(\"motion size; \",h_p.shape)\n","      \n","      \n","      #### show output size cua 1 model\n","      \n","#       h_c_=h_c\n","#       h_p_=h_p      \n","#       print('size of motion output: ', h_p_.size())\n","#       print('size of content output: ', h_c_.size())\n","      \n","  \n","      print('reconstruction from motion and content ')\n","      for i in range(2):\n","        plt.subplot(1,2,i+1)\n","        plt.imshow(np.transpose(rec_[i],(1,2,0)))\n","      plt.show()\n","      \n","      print('reconstruction from motion ')\n","      for i in range(2):\n","        plt.subplot(1,2,i+1)\n","        plt.imshow(np.transpose(rec_motion_[i],(1,2,0)))\n","      plt.show()\n","      \n","      print('reconstruction from content ')\n","      for i in range(2):\n","        plt.subplot(1,2,i+1)\n","        plt.imshow(np.transpose(rec_content_[i],(1,2,0)))\n","      plt.show()\n","                   \n","\n","        \n","        \n","def plot_analogy(x, epoch):\n","    x_c = x[0]\n","\n","    h_c = netEC(x_c)\n","    nrow = 10\n","    row_sz = max_step \n","    to_plot = []\n","    row = [xi[0].data for xi in x]\n","    zeros = torch.zeros(channels, image_width, image_width)\n","    to_plot.append([zeros] + row)\n","    for i in range(nrow):\n","        to_plot.append([x[0][i].data])\n","\n","    for j in range(0, row_sz):\n","        h_p = netEP(x[j]).data\n","        for i in range(nrow):\n","            h_p[i] = h_p[0]\n","        rec = netD([h_c, Variable(h_p)])\n","        for i in range(nrow):\n","            to_plot[i+1].append(rec[i].data.clone())\n","\n","    fname = '%s/analogy/%d.png' % (log_dir, epoch) \n","    utils.save_tensors_image(fname, to_plot)\n","\n","   \n","    \n","\n","# --------- training funtions ------------------------------------\n","def train(x):\n","    netEP.zero_grad()\n","    netEC.zero_grad()\n","    netD.zero_grad()\n","\n","    x_c1 = x[np.random.randint(2, max_step)]\n","    x_c2 = x[0]\n","    x_p1 = x[np.random.randint(2, max_step)]\n","    x_p2 = x[1]\n","\n","    h_c1 = netEC(x_c1)\n","    h_c2 = netEC(x_c2)[0].detach() if content_model[-4:] == 'unet' else netEC(x_c2).detach() # used as target for sim loss\n","    h_p1 = netEP(x_p1) # used for scene discriminator\n","    h_p2 = netEP(x_p2).detach()\n","\n","\n","    # similarity loss: ||h_c1 - h_c2||\n","    sim_loss = mse_criterion(h_c1[0] if content_model[-4:] == 'unet' else h_c1, h_c2)\n","\n","\n","    # reconstruction loss: ||D(h_c1, h_p1), x_p1|| \n","    rec = netD([h_c1, h_p1])\n","    rec_loss = mse_criterion(rec, x_p1)\n","\n","    # scene discriminator loss: maximize entropy of output\n","    target = torch.cuda.FloatTensor(batch_size, 1).fill_(0.5)\n","    out = netC([h_p1, h_p2])\n","    sd_loss = bce_criterion(out, Variable(target))\n","\n","    # full loss\n","    loss = sim_loss + rec_loss + sd_weight*sd_loss\n","    loss.backward()\n","\n","    optimizerEC.step()\n","    optimizerEP.step()\n","    optimizerD.step()\n","\n","    return sim_loss.data.cpu().numpy(),rec_loss.data.cpu().numpy(), sd_loss.data.cpu().numpy()\n","\n","  \n","def train_scene_discriminator(x):\n","  \n","    netC.zero_grad() ############# Sets gradients of all model parameters to zero.\n","\n","    target = torch.cuda.FloatTensor(batch_size, 1)\n","\n","    x1 = x[0]\n","    x2 = x[1]\n","    \n","    h_p1 = netEP(x1).detach()\n","    h_p2 = netEP(x2).detach()\n","\n","    half = int(batch_size/2)\n","    rp = torch.randperm(half).cuda()\n","    h_p2[:half] = h_p2[rp]\n","    target[:half] = 1\n","    target[half:] = 0\n","\n","    out = netC([h_p1, h_p2])\n","    bce = bce_criterion(out, Variable(target))\n","\n","    bce.backward()\n","    optimizerC.step()\n","\n","    acc =out[:half].gt(0.5).sum() + out[half:].le(0.5).sum()\n","    return bce.data.cpu().numpy(), acc.data.cpu().numpy()/batch_size\n","\n","\n","  \n","# --------- training loop ------------------------------------\n","for epoch in range(start_epoch, niter):\n","  \n","    netEP.train()\n","    netEC.train()\n","    netD.train()\n","    netC.train()\n","    \n","    epoch_sim_loss, epoch_rec_loss, epoch_sd_loss, epoch_sd_acc = 0, 0, 0, 0\n","\n","    progress = progressbar.ProgressBar(maxval=epoch_size).start()\n","    for i in range(epoch_size):\n","        progress.update(i+1)\n","        x = next(training_batch_generator)\n","\n","        # train scene discriminator\n","        _, sd_acc = train_scene_discriminator(x)\n","#         epoch_sd_loss += sd_loss\n","        epoch_sd_acc += sd_acc\n","\n","        # train main model\n","        sim_loss, rec_loss, sd_loss = train(x)\n","        epoch_sim_loss += sim_loss\n","        epoch_rec_loss += rec_loss\n","        epoch_sd_loss += sd_loss\n","        \n","#         if (epoch_size+1) % 2 == 0:\n","#           print('type of x: ',type(x))\n","#           print('size of x: ', len(x))\n","          \n","#           print('size of x: ', len(x[1]))\n","#           print('size of x: ', len(x[1][1]))\n","#           print('size of x: ', len(x[1][1][1]))\n","          \n","\n","\n","    progress.finish()\n","    utils.clear_progressbar()\n","\n","    netEP.eval()\n","    netEC.eval()\n","    netD.eval()\n","    # plot some stuff\n","    x = next(testing_batch_generator)\n","    plot_rec(x, epoch)\n","    \n","\n","    print('[%02d] rec loss: %.4f | sim loss: %.6f | scene disc acc: %.3f%% | sd_loss:%.4f (%d)' % (epoch, epoch_rec_loss/epoch_size, epoch_sim_loss/epoch_size, 100*epoch_sd_acc/epoch_size, epoch_sd_loss/epoch_size, epoch*epoch_size*batch_size))\n","\n","    # save the model\n","    \n","    if (epoch+1) % 20==0:\n","      state = {'epoch': epoch + 1, 'state_dict_netD': netD.state_dict(), 'state_dict_netEP': netEP.state_dict(), 'state_dict_netEC': netEC.state_dict(), 'state_dict_netC': netC.state_dict(),\n","             'optimizerC': optimizerC.state_dict(), 'optimizerD': optimizerD.state_dict(), 'optimizerEP': optimizerEP.state_dict(), 'optimizerEC': optimizerEC.state_dict(),}\n","      torch.save(state, '%s/model_state_epoch%d.pth' % (log_dir,epoch+1))\n","    \n","       \n","#     torch.save({\n","#         'netD': netD,\n","#         'netEP': netEP,\n","#         'netEC': netEC,},\n","#         '%s/model.pth' % log_dir)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"x0U-C-zpeEmE","colab_type":"text"},"cell_type":"markdown","source":["### Save model for testing"]},{"metadata":{"id":"ND4lg272zzwi","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","import torch  \n","  \n","  \n","# save the model\n","torch.save({\n","        'netD': netD,\n","        'netEP': netEP,\n","        'netEC': netEC,},\n","        '%s/model.pth' % log_dir)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"THm9MCpN2wOb","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QQiyaTMUe0RN","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"Wr6s3XXIZrRf","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","from torchvision import datasets, transforms\n","from torch.autograd import Variable\n","import random\n","\n","\n","# t=[[[1,2],[6,4],[8,9]], [3,4], [5,6]]\n","\n","# print(len(t[0][1]))\n","\n","# print(\"=============================\")\n","\n","# a=torch.randn(2,3)\n","# print(a)\n","\n","# a_=torch.randn(2,3)\n","# print(a_)\n","\n","\n","\n","# b=torch.cat([a,a_],1)\n","# print(b)\n","\n","# print('===========================')\n","# c=torch.range(1,16)\n","# print(c)\n","# c_=c.view(-1,2)\n","# print(c_)\n","\n","# print('============================')\n","\n","# target = torch.cuda.FloatTensor(5, 1).fill_(0.5)\n","# print(target)\n","# print(Variable(target))\n"," \n","  \n","target_n =torch.cuda.FloatTensor(10,1)\n","print(target_n)\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IQ_hFYX4ip6a","colab_type":"text"},"cell_type":"markdown","source":["### Test_loading data"]},{"metadata":{"id":"ebmS6xxoivQK","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import argparse\n","import os\n","import random\n","import numpy as np\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import utils\n","import itertools\n","import progressbar\n","\n","from data.moving_mnist import MovingMNIST\n","import matplotlib.pyplot as plt\n","\n","\n","## hyper parameter\n","\n","lr=0.002\n","beta1=0.5\n","batch_size=100\n","log_dir='logs'\n","\n","data_root_x=''\n","optimizer='adam'\n","niter=200\n","seed=1\n","epoch_size=600\n","content_dim=128\n","pose_dim=10\n","image_width=64\n","channels=3\n","dataset='moving_mnist'\n","max_step=20\n","sd_weight=0.0001\n","sd_nf=100\n","content_model='dcgan_unet'\n","pose_model='dcgan'\n","data_threads=5\n","normalize='store_true'\n","data_type='drnet'\n","\n","\n","\n","\n","name = 'content_model=%s\\npose_model=%s\\ncontent_dim=%d\\npose_dim=%d\\nmax_step=%d\\nsd_weight=%.3f\\nlr=%.3f\\nsd_nf=%d\\nnormalize=%s' % (content_model, pose_model, content_dim, pose_dim, max_step, sd_weight, lr, sd_nf, normalize)\n","log_dir = '%s/%s%dx%d/%s' % (log_dir, dataset, image_width, image_width, 'xxx')\n","\n","# os.makedirs('%s/rec/' % log_dir, exist_ok=True)\n","# os.makedirs('%s/analogy/' % log_dir, exist_ok=True)\n","\n","print(name)\n","\n","print(log_dir)\n","\n","print(\"Random Seed: \", seed)\n","random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","dtype = torch.cuda.FloatTensor\n","\n","\n","# --------- load a dataset ------------------------------------\n","\n","train_data = MovingMNIST(\n","                train=True,\n","                data_root=data_root_x,\n","                seq_len=max_step,\n","                image_size=image_width,\n","                num_digits=2)\n","\n","\n","\n","# train_data, test_data = utils.load_dataset(dataset,data_root_x,max_step,image_width,data_type)\n","\n","# train_loader = DataLoader(train_data,\n","#                           num_workers=data_threads,\n","#                           batch_size=batch_size,\n","#                           shuffle=True,\n","#                           drop_last=True,\n","#                           pin_memory=True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FDRAQw4Ykbaz","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip3 install scipy "],"execution_count":0,"outputs":[]}]}